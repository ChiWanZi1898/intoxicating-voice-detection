{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/mazeyu/Desktop/CMU/20fall/18797/project',\n",
       " '/Users/mazeyu/opt/anaconda3/envs/mlsp/lib/python38.zip',\n",
       " '/Users/mazeyu/opt/anaconda3/envs/mlsp/lib/python3.8',\n",
       " '/Users/mazeyu/opt/anaconda3/envs/mlsp/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/Users/mazeyu/opt/anaconda3/envs/mlsp/lib/python3.8/site-packages',\n",
       " '/Users/mazeyu/opt/anaconda3/envs/mlsp/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/Users/mazeyu/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/Users/mazeyu/Desktop/CMU/20fall/18797/project/data\"\n",
    "CONF_PATH = \"/Users/mazeyu/Desktop/CMU/20fall/18797/project/opensmile/opensmile/config/is09-13/IS11_speaker_state.conf\"\n",
    "OPENSMILE_PATH = \"/Users/mazeyu/Desktop/CMU/20fall/18797/project/opensmile/opensmile/build/progsrc/smilextract/SMILExtract\"\n",
    "\n",
    "DOC_PATH = 'alc_original/DOC/IS2011CHALLENGE'\n",
    "\n",
    "DATA_PATH = 'alc_original'\n",
    "TRAIN_TABLE = 'TRAIN.TBL'\n",
    "D1_TABLE = 'D1.TBL'\n",
    "D2_TABLE = 'D2.TBL'\n",
    "TEST_TABLE = 'TESTMAPPING.txt'\n",
    "SR = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALCDataset:\n",
    "    def __init__(self, path):\n",
    "        self.dataset_path = path\n",
    "        self.__load_meta_file()\n",
    "\n",
    "    def __process_meta(self, meta):\n",
    "        meta['file_name'] = meta['file_name'].map(lambda x: x[x.find('/') + 1:].lower())\n",
    "        meta['file_name'] = meta['file_name'].map(lambda x: x[:-8] + 'm' + x[-7:])\n",
    "        meta['session'] = meta['file_name'].map(lambda x: x[:x.find('/')])\n",
    "        meta['label'] = meta['user_state'].map(lambda x: 1 if x == 'I' else 0)\n",
    "        return meta\n",
    "    \n",
    "    def __extract_feature(self, wav_input_path, csv_output_path, conf_path):\n",
    "        subprocess.run([OPENSMILE_PATH, \"-C\", conf_path, \"-I\", wav_input_path, \"-csvoutput\", csv_output_path])\n",
    "        \n",
    "        \n",
    "    def extract_feature(self, split, conf_path):\n",
    "        split = split.lower()\n",
    "        assert split in ('train', 'd1', 'd2', 'test')\n",
    "        meta = getattr(self, f'{split}_meta')\n",
    "        \n",
    "        features = []\n",
    "        for file_name in tqdm(meta['file_name']):\n",
    "            wav_input_path = os.path.join(self.dataset_path, DATA_PATH, file_name)\n",
    "            # csv_output_path = f'{wav_input_path.split(\".\")[0]}.csv'\n",
    "            csv_output_path = \"feature.csv\"\n",
    "            if os.path.exists(csv_output_path):\n",
    "                os.remove(csv_output_path)\n",
    "            # print(wav_input_path, csv_output_path)\n",
    "            self.__extract_feature(wav_input_path, csv_output_path, conf_path)\n",
    "            feature = pd.read_csv(csv_output_path, delimiter=\";\").iloc[0, 2:].to_numpy()\n",
    "            features.append(feature)\n",
    "            \n",
    "            \n",
    "        features = np.stack(features)\n",
    "        \n",
    "        np.save(f'{split}_x.npy', features)\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def __load_meta_file(self):\n",
    "        \"\"\"Load meta file.\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        assert os.path.exists(self.dataset_path)\n",
    "        doc_folder = os.path.join(self.dataset_path, DOC_PATH)\n",
    "        print(doc_folder)\n",
    "\n",
    "        train_meta_path = os.path.join(doc_folder, TRAIN_TABLE)\n",
    "        self.train_meta = pd.read_csv(train_meta_path, sep='\\t', names=['file_name', 'bac', 'user_state'])\n",
    "        self.train_meta = self.__process_meta(self.train_meta)\n",
    "\n",
    "        d1_meta_path = os.path.join(doc_folder, D1_TABLE)\n",
    "        self.d1_meta = pd.read_csv(d1_meta_path, sep='\\t', names=['file_name', 'bac', 'user_state'])\n",
    "        self.d1_meta = self.__process_meta(self.d1_meta)\n",
    "\n",
    "        d2_meta_path = os.path.join(doc_folder, D2_TABLE)\n",
    "        self.d2_meta = pd.read_csv(d2_meta_path, sep='\\t', names=['file_name', 'bac', 'user_state'])\n",
    "        self.d2_meta = self.__process_meta(self.d2_meta)\n",
    "\n",
    "        test_meta_path = os.path.join(doc_folder, TEST_TABLE)\n",
    "        self.test_meta = pd.read_csv(test_meta_path, sep='\\t',\n",
    "                                     names=['file_name', 'bac', 'user_state', 'test_file_name'])\n",
    "        self.test_meta = self.test_meta[['file_name', 'bac', 'user_state']]\n",
    "        self.test_meta = self.__process_meta(self.test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mazeyu/Desktop/CMU/20fall/18797/project/data/alc_original/DOC/IS2011CHALLENGE\n"
     ]
    }
   ],
   "source": [
    "dataset = ALCDataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5400/5400 [29:56<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "f_train = dataset.extract_feature(\"train\", CONF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3960/3960 [23:36<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "f_d1 = dataset.extract_feature(\"d1\", CONF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [09:04<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "f_d2 = dataset.extract_feature(\"d2\", CONF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [14:55<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "f_test = dataset.extract_feature(\"test\", CONF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
